{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Final Project Template\n",
        "\n",
        "This is the template for the final project of the course.\n",
        "\n",
        "Form groups of 3 people, take this template and add your code to it. Choose one of the team member's GitHub and upload it there, so that you can all collaborate."
      ],
      "metadata": {
        "id": "Kuu2rfAWcTbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Imports and Setup"
      ],
      "metadata": {
        "id": "jO5MU32Ue5Qs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "64LShxuXcQ90"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For machine learning (you will probably need to add more)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load the Data\n",
        "\n",
        "We present to you two different datasets. One is for regression and the other for classification. **Chose only one of them**.\n",
        "\n",
        "Here are their characteristics and their original documentation if you want to check it out:\n",
        "\n",
        "#### **Bike Sharing Demand - Regression**\n",
        "\n",
        "**Dataset's description**\n",
        "\n",
        "*Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.*\n",
        "\n",
        "*The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.*\n",
        "\n",
        "*You are provided hourly rental data spanning two years. You must predict the total count of bikes rented during each hour*.\n",
        "\n",
        "Original documentation: https://www.kaggle.com/competitions/bike-sharing-demand/\n",
        "\n",
        "You should be able to download the .csv file from our GitHub:"
      ],
      "metadata": {
        "id": "e2G-xDwzh7ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_sharing_demand_df = pd.read_csv('bike-sharing-demand.csv')"
      ],
      "metadata": {
        "id": "qih3Wbe7y5D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Wine quality - Classification**\n",
        "\n",
        "**Dataset's description**\n",
        "\n",
        "*Two datasets are included, related to red and white vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests*.\n",
        "\n",
        "*These datasets can be viewed as classification or regression tasks.  The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.*\n",
        "\n",
        "*You are provided the physicochemical characteristics of the wine. You must predict the sensory perception (quality) of it (1 - 10).*\n",
        "\n",
        "**It could be seen as a regression or a classification. We recommend to choose the other dataset if you want to perform regression, but you are welcome to attack this problem from a regression perspective too.**\n",
        "\n",
        "Original documentation: https://archive.ics.uci.edu/dataset/186/wine+quality"
      ],
      "metadata": {
        "id": "_bH3xtW64tlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "id": "7LoTj2IqzuYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "wine_quality = fetch_ucirepo(id=186)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = wine_quality.data.features\n",
        "y = wine_quality.data.targets\n",
        "\n",
        "# Put them together in a single dataframe\n",
        "wine_quality_df = pd.concat([X, y], axis=1)"
      ],
      "metadata": {
        "id": "idNwkyDczxig"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose one of them.\n",
        "\n",
        "Now:\n",
        "- Divide your data in the training and test sets. Remember, the EDA is only done with the training set. Use a specific seed (so it is replicable each time you execute). Leave test set aside until the end of the project.\n",
        "- Since we are going to do cross-validation, it is not necessary to divide the train set on validation and train."
      ],
      "metadata": {
        "id": "juX9OcU94zCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train, test = train_test_split(...)"
      ],
      "metadata": {
        "id": "jJMqLOjd447j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "AuFF-Q53j245"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Initial exploration\n",
        "\n",
        "- See the columns of your data\n",
        "- View basic statistics\n",
        "- Check for missing values\n",
        "- Visualize distributions, relationships and correlations between attributes/columns."
      ],
      "metadata": {
        "id": "sTLdpE2Gj60o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here\n",
        "\n",
        "# df.info()\n",
        "# df.describe()\n",
        "# df.isna().sum()\n",
        "# corr_matrix = ...\n",
        "# Plot histograms\n",
        "# ..."
      ],
      "metadata": {
        "id": "AVMQJ9_76N7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Data cleaning\n",
        "\n",
        "- Handle missing values, duplicates, and outliers."
      ],
      "metadata": {
        "id": "xu7Nsui9j-Yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here\n",
        "\n",
        "# Check drop_duplicates() function from pandas\n",
        "# df.fillna(...)"
      ],
      "metadata": {
        "id": "Aehx5Qvs6n3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Feature Engineering\n",
        "\n",
        "- Create new features (if you consider they might be useful) given the existing ones.\n",
        "- Encode categorical variables (if any)\n",
        "- Transform numerical features so that they have similar scales"
      ],
      "metadata": {
        "id": "z-jYBWxkkEpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training"
      ],
      "metadata": {
        "id": "pkNE5W_9kJFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Define Features and Target\n",
        "\n",
        "- Define X (features) and y (target)"
      ],
      "metadata": {
        "id": "_ncvwaIVkMk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X, y = ..."
      ],
      "metadata": {
        "id": "C05IWiFN69Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Train your model and evaluate it using Cross-validation\n",
        "\n",
        "- Import the models that you want to use from sklearn.\n",
        "- Choose some metrics that will let you know how the models are performing.\n",
        "- Use cross-validation to validate them and compare their performances. Choose the best one.\n",
        "- (Optional) Perform a hyperparameter search to improve the training of the model."
      ],
      "metadata": {
        "id": "_rA4dYbXkQ6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluate on test set\n",
        "\n",
        "- Clean and do feature engineering process on test set.\n",
        "- See how the model performs on the test set."
      ],
      "metadata": {
        "id": "1v-W-sCikaDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Conclusions and future work"
      ],
      "metadata": {
        "id": "xaP3PZ4jkmwh"
      }
    }
  ]
}